# Week 1 Quiz
## Question 1
```{r}
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
```
Solution 1:
```{r}
miu <- weighted.mean(x,w)
miu
```
Solution 2:
```{r}
miu <- sum(x*w)/sum(w)
miu
```

## Question 2
Solution 1:
```{r}
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y~x-1))
```
Solution 2:
```{r}
sum(y*x)/sum(x^2)
```

## Question 3
```{r}
data(mtcars)
coef(lm(mpg~wt,data = mtcars))[2]
```

## Question 4
sd(Y)/sd(X) <- 2
cor(Y,X) <- 0.5
slope coefficient for the regression model with Y as the outcome and 
X as the predictor:
cor(Y,X)*sd(Y)/sd(X) = 1

## Question 5
```{r}
1.5*0.4
```

## Question 6
```{r}
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
meanX <- mean(x)
sdX<- sd(x)
first <- (x[1]-meanX)/sdX
first
```

## Question 7
```{r}
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef((lm(y~x)))[1]
```

## Question 8
You know that both the predictor and response have mean 0. 
What can be said about the intercept when you fit a linear regression?       
beta0 <-Bar_Y- Bar_X*beta1  
Answer: It must be identically 0.

## Question 9
This is the least squares estimate, which works out to be the mean in this case.
```{r}
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
```

## Question 10
beta1 <- cor(Y,X) * sd(Y)/sd(X)  
theta1 <- cor(Y,X) * sd(X)/sd(Y)  
beta1/theta1 = sd(Y) ^2 / sd(X)^2  =var(Y)/var(X)



